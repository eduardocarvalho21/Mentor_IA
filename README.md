#  MentorIA - RAG Local com Valida√ß√£o Estrita

O **MentorIA** √© um sistema de **RAG (Retrieval-Augmented Generation)** que roda 100% localmente para analisar documentos t√©cnicos. O foco do projeto √© a **Engenharia de Software** aplicada √† IA para resolver problemas de alucina√ß√£o, privacidade e lat√™ncia.

---

##  Diferenciais de Engenharia

1.  **üõ°Ô∏è Guardrails Anti-Alucina√ß√£o:** Implementa√ß√£o de um *Cosine Similarity Threshold* de `0.50`. Perguntas fora do contexto (ex: "Futebol" em um TCC de Farm√°cia) s√£o bloqueadas matematicamente antes de acionar a LLM.
2.  **‚ùÑÔ∏è Resili√™ncia (Cold Start):** Sistema de **Retry com Backoff Exponencial**. Se o Ollama estiver descarregado da RAM, o backend aguarda e reconecta automaticamente.
3.  **‚ö° Performance:** Uso de √≠ndices **HNSW** no Supabase para buscas vetoriais em milissegundos.
4.  **üèóÔ∏è Arquitetura S√≥lida:** Separa√ß√£o clara entre Ingest√£o (Python), Banco de Dados (Drizzle ORM) e API (Next.js).

---

## üõ†Ô∏è Tech Stack

- **Frontend:** Next.js 14 (App Router), Tailwind CSS.
- **Backend:** Next.js Server Actions & API Routes.
- **Database:** Supabase (PostgreSQL + pgvector).
- **ORM:** Drizzle ORM.
- **AI Engine:** Ollama (Local).
  - Modelo: `llama3.2:1b`
  - Embeddings: `nomic-embed-text`
- **Ingest√£o:** Python scripts.

---

## ‚öôÔ∏è Instala√ß√£o e Configura√ß√£o

```bash
ollama pull llama3.2:1b
ollama pull nomic-embed-text

-- Habilitar extens√£o vetorial
create extension vector;

-- Tabela de Embeddings
create table embeddings (
  id serial primary key,
  content text not null,
  embedding vector(768) -- Compat√≠vel com nomic-embed-text
);

-- √çndice HNSW para performance extrema
create index on embeddings using hnsw (embedding vector_cosine_ops);

# Clone o reposit√≥rio
git clone https://github.com/eduardocarvalho21/Mentor_IA.git

# Entre na pasta
cd Mentor_IA

# Instale as depend√™ncias
npm install

DATABASE_URL=postgres://usuario:senha@host:6543/postgres
NEXT_PUBLIC_API_URL=http://localhost:3000

npm run dev

Acesse http://localhost:3000.

Como Funciona:

Ingest√£o: Script Python quebra o PDF em chunks e salva os vetores no Supabase.

Pergunta: O usu√°rio envia uma d√∫vida.

Valida√ß√£o: O Backend calcula a similaridade. Se < 0.50, retorna "N√£o consta no documento".

Resposta: Se aprovado, o Llama 3.2 recebe o contexto e gera a resposta via Stream.

Licen√ßa
Desenvolvido por Eduardo Pereira de Carvalho.
